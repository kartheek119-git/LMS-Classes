# -*- coding: utf-8 -*-
"""Web_scrapping

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y3nTNkYfdd0R34KOpAI8J8n6j2rgBRRJ
"""

pip install requests beautifulsoup4

import requests
from bs4 import BeautifulSoup
# URL to scrap
url = "http://quotes.toscrape.com/"
# Send a GET request
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Parse the HTML
    soup = BeautifulSoup(response.text, 'html.parser')
    # Find all quote containers
    quotes = soup.find_all("div", class_="quote")
    # Loop through each quote and extract data
    for i, quote in enumerate(quotes[:5]):  # Get first 5 quotes
        text = quote.find("span", class_="text").text  # Quote text
        author = quote.find("small", class_="author").text  # Author name
        tags = [tag.text for tag in quote.find_all("a", class_="tag")]  # List of tags
        print(f"{i+1}. \"{text}\" - {author}")
        print(f"   Tags: {', '.join(tags)}\n")
else:
    print(f"Failed to retrieve the webpage. Status Code: {response.status_code}")

import requests
from bs4 import BeautifulSoup
# Define the city (e.g., New York)
city = "india/hyderabad"
url = f"https://www.timeanddate.com/weather/{city}"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
temp = soup.find("div", class_="h2").text.strip() if soup.find("div", class_="h2") else "N/A"
desc = soup.find("p").text.strip() if soup.find("p") else "N/A"
print(f"Current Weather in Hyderabad: {temp} | {desc}")

import requests
from bs4 import BeautifulSoup
# Product search URL (Example: iPhone)
search_url = "https://www.amazon.in/s?k=iphone&crid=2KQB38CMITIOL&sprefix=iphone%2Caps%2C199&ref=nb_sb_noss_2"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}
# Send GET request
response = requests.get(search_url, headers=headers)
soup = BeautifulSoup(response.text, "html.parser")
# Extract first product name & price
product = soup.select_one("span.a-size-medium")
price = soup.select_one("span.a-price-whole")
# Display product details
if product and price:
    print(f"Product: {product.text.strip()}")
    print(f"Price: Rs.{price.text.strip()}")
else:
    print("Could not find product details.")

import requests
from bs4 import BeautifulSoup
# Wikipedia page URL
url = "https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population"
# Send GET request
response = requests.get(url,headers=headers)
soup = BeautifulSoup(response.text, "html.parser")
# Find the table
table = soup.find("table", class_="wikitable")
# Extract the first 5 countries and their population
for row in table.find_all("tr")[1:6]:  # Skip the header row
    columns = row.find_all("td")
    country = columns[1].text.strip()
    population = columns[2].text.strip()
    print(f"{country}: {population}")

from IPython.display import display, HTML
display(HTML("""
   <p style="font-family:verdana">This is a sample table</p>
  <table>
  <tr>
    <th>Company</th>
    <th>Contact</th>
    <th>Country</th>
  </tr>
  <tr>
    <td>Alfreds Futterkiste</td>
    <td>Maria Anders</td>
    <td>Germany</td>
  </tr>
  <tr>
    <td>Centro comercial Moctezuma</td>
    <td>Francisco Chang</td>
    <td>Mexico</td>
  </tr>
</table>
"""))

